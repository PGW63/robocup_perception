#!/usr/bin/env python3
"""
Human State Detector Node
- utils.pyì˜ ê¸°í•˜í•™ í•¨ìˆ˜ í™œìš©
- ì„œìˆê¸°, ì•‰ì•„ìˆê¸°, ëˆ„ì›Œìˆê¸°, ì†ë“¤ê¸° íŒë³„
- ë””ë²„ê·¸ ì´ë¯¸ì§€ì— ì‚¬ëŒë³„ ìƒíƒœ í‘œì‹œ
"""

import numpy as np
import cv2
from enum import Enum, auto
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
from sensor_msgs.msg import Image, CameraInfo, CompressedImage
from std_msgs.msg import String, ColorRGBA, Bool, Float32MultiArray
from geometry_msgs.msg import Point
from visualization_msgs.msg import Marker, MarkerArray
from ultralytics import YOLO
import tf2_ros
from tf2_ros import TransformBroadcaster
import message_filters

from human_utils.utils import (
    Point3D, Skeleton3D, KeypointIndex, SKELETON_CONNECTIONS,
    angle_3d, angle_3d_on_plane, distance_3d, vector_3d, midpoint_3d,
    JointAngleCalculator
)

class HumanState(Enum):
    UNKNOWN = auto()
    STANDING = auto()      # ì„œìˆê¸°
    SITTING = auto()       # ì•‰ì•„ìˆê¸°
    LYING_DOWN = auto()    # ëˆ„ì›Œìˆê¸°
    HAND_UP_LEFT = auto()  # ì™¼ì† ë“¤ê¸°
    HAND_UP_RIGHT = auto() # ì˜¤ë¥¸ì† ë“¤ê¸°
    HAND_UP_BOTH = auto()  # ì–‘ì† ë“¤ê¸°

STATE_COLORS = {
    HumanState.UNKNOWN: (128, 128, 128),      # íšŒìƒ‰
    HumanState.STANDING: (0, 255, 0),         # ì´ˆë¡
    HumanState.SITTING: (255, 165, 0),        # ì£¼í™©
    HumanState.LYING_DOWN: (255, 0, 0),       # íŒŒë‘
    HumanState.HAND_UP_LEFT: (0, 255, 255),   # ë…¸ë‘
    HumanState.HAND_UP_RIGHT: (0, 255, 255),  # ë…¸ë‘
    HumanState.HAND_UP_BOTH: (0, 0, 255),     # ë¹¨ê°•
}

class HumanStateDetector:
    """Rule-based ê¸°í•˜í•™ìœ¼ë¡œ ì‚¬ëŒ ìƒíƒœ íŒë³„"""
    
    def __init__(self):
        # === ì† ë“¤ê¸° ì„ê³„ê°’ ===
        self.hand_up_wrist_above_shoulder = True  # ì†ëª©ì´ ì–´ê¹¨ë³´ë‹¤ ìœ„
        self.hand_up_elbow_angle_min = 150.0       # íŒ”ê¿ˆì¹˜ ìµœì†Œ ê°ë„ (90ë„ ì´ìƒì´ë©´ í´ì§)
        
        # === ì•‰ê¸° ì„ê³„ê°’ ===
        self.sitting_knee_angle_max = 130.0      # ë¬´ë¦ ê°ë„ (130ë„ ì´í•˜ë©´ êµ¬ë¶€ë¦¼)
        self.sitting_hip_angle_max = 130.0       # ì—‰ë©ì´ ê°ë„ (130ë„ ì´í•˜ë©´ ì•‰ìŒ)
        
        # === ëˆ„ì›Œìˆê¸° ì„ê³„ê°’ ===
        self.lying_torso_horizontal_threshold = 20.0  # ëª¸í†µ ê¸°ìš¸ê¸° (45ë„ ì´í•˜ë©´ ëˆ„ì›€)
        
        # === ì„œìˆê¸° ì„ê³„ê°’ ===
        self.standing_knee_angle_min = 150.0     # ë¬´ë¦ ê°ë„ (150ë„ ì´ìƒì´ë©´ í´ì§)
        self.standing_hip_angle_min = 150.0      # ì—‰ë©ì´ ê°ë„ (150ë„ ì´ìƒì´ë©´ í´ì§)

    def detect_state(self, skeleton: Skeleton3D) -> Tuple[HumanState, Dict[str, float]]:
        """
        ìŠ¤ì¼ˆë ˆí†¤ì—ì„œ ìƒíƒœ íŒë³„
        
        Returns:
            Tuple[HumanState, Dict]: (ìƒíƒœ, íŒë³„ì— ì‚¬ìš©ëœ ê°ë„ë“¤)
        """
        angles = JointAngleCalculator.get_all_angles(skeleton)
        
        # 1. ì† ë“¤ê¸° ë¨¼ì € ì²´í¬ (ë‹¤ë¥¸ ìƒíƒœì™€ ë³‘í–‰ ê°€ëŠ¥)
        hand_state = self._detect_hand_up(skeleton, angles)
        if hand_state:
            return hand_state, angles
        
        # 2. ëˆ„ì›Œìˆê¸° ì²´í¬ (ì£¼ì„ì²˜ë¦¬)
        # if self._is_lying_down(skeleton, angles):
        #     return HumanState.LYING_DOWN, angles
        
        # 3. ì•‰ì•„ìˆê¸° ì²´í¬ (ì£¼ì„ì²˜ë¦¬)
        # if self._is_sitting(skeleton, angles):
        #     return HumanState.SITTING, angles
        
        # 4. ì„œìˆê¸° ì²´í¬ (ì£¼ì„ì²˜ë¦¬)
        # if self._is_standing(skeleton, angles):
        #     return HumanState.STANDING, angles
        
        return HumanState.UNKNOWN, angles
    
    def _detect_hand_up(self, skel: Skeleton3D, angles: Dict) -> Optional[HumanState]:
        """ì† ë“¤ê¸° ê°ì§€"""
        left_up = self._is_hand_up(skel, "left", angles)
        right_up = self._is_hand_up(skel, "right", angles)
        
        if left_up and right_up:
            return HumanState.HAND_UP_BOTH
        elif left_up:
            return HumanState.HAND_UP_LEFT
        elif right_up:
            return HumanState.HAND_UP_RIGHT
        return None
    
    def _is_hand_up(self, skel: Skeleton3D, side: str, angles: Dict) -> bool:
        """í•œ ìª½ ì†ì´ ë“¤ë ¤ìˆëŠ”ì§€ í™•ì¸"""
        if side == "left":
            shoulder_idx = KeypointIndex.LEFT_SHOULDER
            elbow_idx = KeypointIndex.LEFT_ELBOW
            wrist_idx = KeypointIndex.LEFT_WRIST
            elbow_angle_key = "left_elbow"
        else:
            shoulder_idx = KeypointIndex.RIGHT_SHOULDER
            elbow_idx = KeypointIndex.RIGHT_ELBOW
            wrist_idx = KeypointIndex.RIGHT_WRIST
            elbow_angle_key = "right_elbow"
        
        # í•„ìš”í•œ í‚¤í¬ì¸íŠ¸ í™•ì¸
        if not all(skel.has_point(i) for i in [shoulder_idx, elbow_idx, wrist_idx]):
            return False
        
        shoulder = skel.keypoints[shoulder_idx]
        wrist = skel.keypoints[wrist_idx]
        
        # ì¡°ê±´ 1: ì†ëª©ì´ ì–´ê¹¨ë³´ë‹¤ ìœ„ì— ìˆëŠ”ì§€
        # ì¹´ë©”ë¼ ì¢Œí‘œê³„: Yê°€ ì•„ë˜ë¡œ ì¦ê°€í•˜ë¯€ë¡œ, wrist.y < shoulder.yì´ë©´ ìœ„
        wrist_above_shoulder = wrist.y < shoulder.y
        
        # ì¡°ê±´ 2: íŒ”ê¿ˆì¹˜ ê°ë„ê°€ ì¶©ë¶„íˆ í´ì ¸ìˆëŠ”ì§€
        elbow_angle = angles.get(elbow_angle_key)
        elbow_extended = elbow_angle is not None and elbow_angle >= self.hand_up_elbow_angle_min
        
        return wrist_above_shoulder
    
    # === ì•„ë˜ í•¨ìˆ˜ë“¤ ì£¼ì„ì²˜ë¦¬ ===
    # def _is_lying_down(self, skel: Skeleton3D, angles: Dict) -> bool:
    #     """ëˆ„ì›ŒìˆëŠ” ìì„¸ ê°ì§€"""
    #     # ì–´ê¹¨ì™€ ì—‰ë©ì´ê°€ í•„ìš”
    #     if not (skel.has_point(KeypointIndex.LEFT_SHOULDER) and 
    #             skel.has_point(KeypointIndex.LEFT_HIP)):
    #         if not (skel.has_point(KeypointIndex.RIGHT_SHOULDER) and 
    #                 skel.has_point(KeypointIndex.RIGHT_HIP)):
    #             return False
    #     
    #     # ì™¼ìª½ ë˜ëŠ” ì˜¤ë¥¸ìª½ ì–´ê¹¨-ì—‰ë©ì´ ì‚¬ìš©
    #     if skel.has_point(KeypointIndex.LEFT_SHOULDER) and skel.has_point(KeypointIndex.LEFT_HIP):
    #         shoulder = skel.keypoints[KeypointIndex.LEFT_SHOULDER]
    #         hip = skel.keypoints[KeypointIndex.LEFT_HIP]
    #     else:
    #         shoulder = skel.keypoints[KeypointIndex.RIGHT_SHOULDER]
    #         hip = skel.keypoints[KeypointIndex.RIGHT_HIP]
    #     
    #     # ëª¸í†µ ë²¡í„° (ì—‰ë©ì´ â†’ ì–´ê¹¨)
    #     torso_vec = vector_3d(hip, shoulder)
    #     
    #     # ìˆ˜ì§ ë²¡í„° (ì¹´ë©”ë¼ ì¢Œí‘œê³„ì—ì„œ -Yê°€ ìœ„)
    #     vertical = np.array([0, -1, 0])
    #     
    #     # ëª¸í†µê³¼ ìˆ˜ì§ì˜ ê°ë„
    #     torso_norm = np.linalg.norm(torso_vec)
    #     if torso_norm < 1e-6:
    #         return False
    #     
    #     cos_angle = np.dot(torso_vec / torso_norm, vertical)
    #     torso_angle_from_vertical = np.degrees(np.arccos(np.clip(np.abs(cos_angle), 0, 1)))
    #     
    #     # ìˆ˜ì§ì—ì„œ 45ë„ ì´ìƒ ë²—ì–´ë‚˜ë©´ (ìˆ˜í‰ì— ê°€ê¹Œìš°ë©´) ëˆ„ì›ŒìˆìŒ
    #     return torso_angle_from_vertical > (90 - self.lying_torso_horizontal_threshold)
    
    # def _is_sitting(self, skel: Skeleton3D, angles: Dict) -> bool:
    #     """ì•‰ì•„ìˆëŠ” ìì„¸ ê°ì§€"""
    #     # ë¬´ë¦ ê°ë„ ì²´í¬
    #     left_knee = angles.get("left_knee")
    #     right_knee = angles.get("right_knee")
    #     
    #     # ì—‰ë©ì´ ê°ë„ ì²´í¬
    #     left_hip = angles.get("left_hip")
    #     right_hip = angles.get("right_hip")
    #     
    #     # ë¬´ë¦ì´ êµ¬ë¶€ëŸ¬ì ¸ ìˆê³  ì—‰ë©ì´ë„ êµ¬ë¶€ëŸ¬ì ¸ ìˆìœ¼ë©´ ì•‰ìŒ
    #     knee_bent = False
    #     hip_bent = False
    #     
    #     if left_knee is not None and left_knee < self.sitting_knee_angle_max:
    #         knee_bent = True
    #     if right_knee is not None and right_knee < self.sitting_knee_angle_max:
    #         knee_bent = True
    #     
    #     if left_hip is not None and left_hip < self.sitting_hip_angle_max:
    #         hip_bent = True
    #     if right_hip is not None and right_hip < self.sitting_hip_angle_max:
    #         hip_bent = True
    #     
    #     return knee_bent and hip_bent
    
    # def _is_standing(self, skel: Skeleton3D, angles: Dict) -> bool:
    #     """ì„œìˆëŠ” ìì„¸ ê°ì§€"""
    #     # ë¬´ë¦ ê°ë„ ì²´í¬
    #     left_knee = angles.get("left_knee")
    #     right_knee = angles.get("right_knee")
    #     
    #     # ì—‰ë©ì´ ê°ë„ ì²´í¬
    #     left_hip = angles.get("left_hip")
    #     right_hip = angles.get("right_hip")
    #     
    #     # ë¬´ë¦ì´ í´ì ¸ ìˆê³  ì—‰ë©ì´ë„ í´ì ¸ ìˆìœ¼ë©´ ì„œìˆìŒ
    #     knee_straight = False
    #     hip_straight = False
    #     
    #     if left_knee is not None and left_knee >= self.standing_knee_angle_min:
    #         knee_straight = True
    #     if right_knee is not None and right_knee >= self.standing_knee_angle_min:
    #         knee_straight = True
    #     
    #     if left_hip is not None and left_hip >= self.standing_hip_angle_min:
    #         hip_straight = True
    #     if right_hip is not None and right_hip >= self.standing_hip_angle_min:
    #         hip_straight = True
    #     
    #     # ë‘˜ ë‹¤ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì„œìˆë‹¤ê³  ê°€ì •
    #     if left_knee is None and right_knee is None:
    #         knee_straight = True
    #     if left_hip is None and right_hip is None:
    #         hip_straight = True
    #     
    #     return knee_straight and hip_straight


# ============================================================
# ROS2 Node
# ============================================================
class HumanStateDetectorNode(Node):
    def __init__(self):
        super().__init__('human_state_detector_node')
        
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter("image_topic", "/camera/camera/color/image_raw/compressed")
        self.declare_parameter("camera_info_topic", "/camera/camera/color/camera_info")
        self.declare_parameter("depth_topic", "/camera/camera/aligned_depth_to_color/image_raw")
        self.declare_parameter("camera_frame", "camera_color_optical_frame")
        self.declare_parameter("world_frame", "base")
        
        self.declare_parameter("yolo_model", "yolov8s-pose.pt")
        self.declare_parameter("yolo_conf", 0.5)
        self.declare_parameter("yolo_device", "cuda")
        
        self.declare_parameter("publish_markers", True)
        self.declare_parameter("min_keypoint_conf", 0.3)
        self.declare_parameter("min_detection_frames", 5)  # ìµœì†Œ ì—°ì† ê°ì§€ í”„ë ˆì„ ìˆ˜
        
        # íŒŒë¼ë¯¸í„° ë¡œë“œ
        self.image_topic = self.get_parameter("image_topic").value
        self.camera_info_topic = self.get_parameter("camera_info_topic").value
        self.depth_topic = self.get_parameter("depth_topic").value
        self.camera_frame = self.get_parameter("camera_frame").value
        self.world_frame = self.get_parameter("world_frame").value
        
        self.publish_markers = self.get_parameter("publish_markers").value
        self.min_keypoint_conf = self.get_parameter("min_keypoint_conf").value
        self.min_detection_frames = self.get_parameter("min_detection_frames").value
        
        # ê°•ê±´ì„± ê²€ì¦ - hand up ê°ì§€ ì¹´ìš´í„°
        self.hand_up_counter = 0
        self.hand_up_detected = False
        
        # QoS ì„¤ì • (ì´ë¯¸ì§€ëŠ” Reliable ì‚¬ìš©)
        qos_best_effort = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            history=HistoryPolicy.KEEP_LAST,
            depth=5,
        )
        
        qos_reliable = QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            history=HistoryPolicy.KEEP_LAST,
            depth=5,
        )
        
        # CvBridge
        # self.bridge = CvBridge()
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        model_name = self.get_parameter("yolo_model").value
        device = self.get_parameter("yolo_device").value
        self.yolo_conf = self.get_parameter("yolo_conf").value
        
        self.get_logger().info(f"Loading YOLO model: {model_name} on {device}")
        self.model = YOLO(model_name)
        if device == 'cuda':
            self.model.to('cuda')
        
        # ì¹´ë©”ë¼ ì •ë³´
        self.camera_matrix = None
        self.dist_coeffs = None
        self.depth_image = None

        # ìƒíƒœ í”Œë˜ê·¸
        self.stop_flag = False
        
        # TF
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        
        # ìƒíƒœ ê°ì§€ê¸°
        self.state_detector = HumanStateDetector()

        # self.sub_img_compressed = self.create_subscription(CompressedImage, self.image_topic, self.on_image_compresse, qos_reliable)
        self.sub_info = self.create_subscription(CameraInfo, self.camera_info_topic, self.on_camera_info, 10)

        self.image_sub = message_filters.Subscriber(self, CompressedImage, self.image_topic, qos_profile=qos_best_effort)
        self.depth_sub = message_filters.Subscriber(self, Image, self.depth_topic, qos_profile=qos_best_effort)

        self.ats = message_filters.ApproximateTimeSynchronizer([self.image_sub, self.depth_sub], queue_size=10, slop=0.1)
        self.ats.registerCallback(self.synchronized_callback)
        # self.stop_flag ë³€ê²½
        self.sub_flag = self.create_subscription(Bool, "/human/resume", self.flag_callback, 10)
        
        # ë°œí–‰ì (Reliable QoSë¡œ í†µì¼)
        self.pub_state = self.create_publisher(String, "/human/states", qos_reliable)
        self.pub_markers = self.create_publisher(MarkerArray, "/human/skeleton_markers", qos_reliable)
        self.pub_debug = self.create_publisher(Image, "/human/debug_image", qos_best_effort)
        self.pub_hand_up = self.create_publisher(Bool, "/human/hand_up_detected", 10)
        self.pub_hand_up_bbox = self.create_publisher(Float32MultiArray, "/human/hand_up_bbox", 10)
        
        self.get_logger().info(f"Human State Detector Node initialized")
        self.get_logger().info(f"  Image: {self.image_topic}")
        self.get_logger().info(f"  Camera frame: {self.camera_frame}")

        self.get_logger().debug("Log level set to DEBUG for detailed tracing.")
    
    def flag_callback(self, msg: Bool):
        """stop_flag ì—…ë°ì´íŠ¸"""
        self.stop_flag = not msg.data
        if self.stop_flag:
            self.get_logger().info("â¸ï¸ Human state detection paused")
        else:
            self.get_logger().info("â–¶ï¸ Human state detection resumed")
    
    def on_camera_info(self, msg: CameraInfo):
        """ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ìˆ˜ì‹ """
        self.camera_matrix = np.array(msg.k).reshape((3, 3))
        self.dist_coeffs = np.array(msg.d)
        self.destroy_subscription(self.sub_info)
        self.get_logger().info("Camera info received and camera matrix set.")
    
    def pixel_to_3d(self, u: int, v: int, depth_m: float) -> Optional[Point3D]:
        """2D í”½ì…€ ì¢Œí‘œ + ê¹Šì´ â†’ 3D ì¢Œí‘œ"""
        if self.camera_matrix is None:
            return None
        
        fx = self.camera_matrix[0, 0]
        fy = self.camera_matrix[1, 1]
        cx = self.camera_matrix[0, 2]
        cy = self.camera_matrix[1, 2]
        
        x = (u - cx) * depth_m / fx
        y = (v - cy) * depth_m / fy
        z = depth_m
        
        return Point3D(x, y, z)
    
    def get_depth_at_pixel(self, u: int, v: int) -> Optional[float]:
        """í”½ì…€ ìœ„ì¹˜ì˜ ê¹Šì´ê°’ (ë¯¸í„°)"""
        if self.depth_image is None:
            return None
        
        h, w = self.depth_image.shape[:2]
        u = int(np.clip(u, 0, w - 1))
        v = int(np.clip(v, 0, h - 1))
        
        y1, y2 = max(0, v - 2), min(h, v + 3)
        x1, x2 = max(0, u - 2), min(w, u + 3)
        patch = self.depth_image[y1:y2, x1:x2]
        
        valid = patch[(patch > 0) & np.isfinite(patch)]
        if valid.size == 0:
            return None
        
        depth_raw = float(np.median(valid))
        
        if self.depth_image.dtype == np.uint16:
            return depth_raw / 1000.0
        return depth_raw
    
    def extract_skeleton_3d(self, keypoints_2d: np.ndarray, img_shape: Tuple[int, int]) -> Skeleton3D:
        """2D í‚¤í¬ì¸íŠ¸ì—ì„œ 3D ìŠ¤ì¼ˆë ˆí†¤ ì¶”ì¶œ"""
        h, w = img_shape[:2]
        skeleton = Skeleton3D(frame_id=self.camera_frame)
        
        for kp_idx in range(17):
            u, v, conf = keypoints_2d[kp_idx]
            
            if conf < self.min_keypoint_conf:
                continue
            
            u, v = int(u), int(v)
            if u < 0 or u >= w or v < 0 or v >= h:
                continue
            
            depth = self.get_depth_at_pixel(u, v)
            if depth is None or depth <= 0 or depth > 10.0:
                continue
            
            pt_3d = self.pixel_to_3d(u, v, depth)
            if pt_3d:
                pt_3d.confidence = float(conf)
                skeleton.keypoints[kp_idx] = pt_3d
        
        return skeleton
    
    def draw_state_on_image(self, image: np.ndarray, bbox: np.ndarray, 
                            state: HumanState, person_id: int,
                            angles: Dict[str, Optional[float]]) -> np.ndarray:
        """ì´ë¯¸ì§€ì— ìƒíƒœ ì •ë³´ ê·¸ë¦¬ê¸°"""
        x1, y1, x2, y2 = map(int, bbox[:4])
        
        # ìƒíƒœë³„ ìƒ‰ìƒ
        color = STATE_COLORS.get(state, (128, 128, 128))
        
        # ë°”ìš´ë”© ë°•ìŠ¤
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸ ë°°ê²½
        state_text = f"P{person_id}: {state.name}"
        (text_w, text_h), _ = cv2.getTextSize(state_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
        cv2.rectangle(image, (x1, y1 - text_h - 10), (x1 + text_w + 10, y1), color, -1)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸
        cv2.putText(image, state_text, (x1 + 5, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ê°ë„ ì •ë³´ (ë°•ìŠ¤ ì•„ë˜)
        y_offset = y2 + 20
        for name, angle in angles.items():
            if angle is not None:
                angle_text = f"{name}: {angle:.1f}"
                cv2.putText(image, angle_text, (x1, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
                y_offset += 15
                if y_offset > y2 + 100:  # ë„ˆë¬´ ë§ìœ¼ë©´ ìë¥´ê¸°
                    break
        
        return image
    
    def create_skeleton_markers(self, skeleton: Skeleton3D, person_id: int, 
                                state: HumanState, stamp) -> MarkerArray:
        """ìŠ¤ì¼ˆë ˆí†¤ ë§ˆì»¤ ìƒì„±"""
        markers = MarkerArray()
        
        # ìƒíƒœë³„ ìƒ‰ìƒ
        color_bgr = STATE_COLORS.get(state, (128, 128, 128))
        color_rgb = (color_bgr[2] / 255.0, color_bgr[1] / 255.0, color_bgr[0] / 255.0)
        
        # ê´€ì ˆ ì  ë§ˆì»¤
        joint_marker = Marker()
        joint_marker.header.frame_id = skeleton.frame_id
        joint_marker.header.stamp = stamp
        joint_marker.ns = f"skeleton_{person_id}_joints"
        joint_marker.id = 0
        joint_marker.type = Marker.SPHERE_LIST
        joint_marker.action = Marker.ADD
        joint_marker.scale.x = 0.05
        joint_marker.scale.y = 0.05
        joint_marker.scale.z = 0.05
        joint_marker.color.r = color_rgb[0]
        joint_marker.color.g = color_rgb[1]
        joint_marker.color.b = color_rgb[2]
        joint_marker.color.a = 1.0
        joint_marker.lifetime.sec = 0
        joint_marker.lifetime.nanosec = 200000000
        
        for idx, pt in skeleton.keypoints.items():
            joint_marker.points.append(pt.to_ros_point())
        
        markers.markers.append(joint_marker)
        
        # ë¼ˆëŒ€ ë§ˆì»¤
        bone_marker = Marker()
        bone_marker.header.frame_id = skeleton.frame_id
        bone_marker.header.stamp = stamp
        bone_marker.ns = f"skeleton_{person_id}_bones"
        bone_marker.id = 1
        bone_marker.type = Marker.LINE_LIST
        bone_marker.action = Marker.ADD
        bone_marker.scale.x = 0.02
        bone_marker.color.r = color_rgb[0]
        bone_marker.color.g = color_rgb[1]
        bone_marker.color.b = color_rgb[2]
        bone_marker.color.a = 0.8
        bone_marker.lifetime.sec = 0
        bone_marker.lifetime.nanosec = 200000000
        
        for (start_idx, end_idx) in SKELETON_CONNECTIONS:
            if skeleton.has_point(start_idx) and skeleton.has_point(end_idx):
                bone_marker.points.append(skeleton.keypoints[start_idx].to_ros_point())
                bone_marker.points.append(skeleton.keypoints[end_idx].to_ros_point())
        
        markers.markers.append(bone_marker)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸ ë§ˆì»¤
        center = skeleton.get_center()
        if center:
            text_marker = Marker()
            text_marker.header.frame_id = skeleton.frame_id
            text_marker.header.stamp = stamp
            text_marker.ns = f"skeleton_{person_id}_state"
            text_marker.id = 2
            text_marker.type = Marker.TEXT_VIEW_FACING
            text_marker.action = Marker.ADD
            text_marker.pose.position = center.to_ros_point()
            text_marker.pose.position.y -= 0.3  # ë¨¸ë¦¬ ìœ„ (ì¹´ë©”ë¼ ì¢Œí‘œê³„)
            text_marker.scale.z = 0.15
            text_marker.color.r = 1.0
            text_marker.color.g = 1.0
            text_marker.color.b = 1.0
            text_marker.color.a = 1.0
            text_marker.text = state.name
            text_marker.lifetime.sec = 0
            text_marker.lifetime.nanosec = 200000000
            
            markers.markers.append(text_marker)
        
        return markers
    
    def synchronized_callback(self, image_msg: CompressedImage, depth_msg: Image):
        """ì´ë¯¸ì§€ ì½œë°±"""
        # self.get_logger().debug("ğŸ”µ on_image called - ì½œë°± í•¨ìˆ˜ ì‹¤í–‰ë¨!")
        
        if self.stop_flag:
            self.get_logger().info("â¸ï¸ Processing is paused due to stop_flag.")
            return
        
        
        try:
            self.bgr = cv2.imdecode(np.frombuffer(image_msg.data, dtype=np.uint8), cv2.IMREAD_COLOR)
            self.rgb = cv2.cvtColor(self.bgr, cv2.COLOR_BGR2RGB)
        except Exception as e:
            self.get_logger().warn(f"Image conversion failed: {e}")
            return

        # Depth ì´ë¯¸ì§€ ë³€í™˜ (encoding í™•ì¸)
        try:
            if depth_msg.encoding == '16UC1':
                self.depth_image = np.frombuffer(depth_msg.data, dtype=np.uint16).reshape((depth_msg.height, depth_msg.width))
            elif depth_msg.encoding == '32FC1':
                self.depth_image = np.frombuffer(depth_msg.data, dtype=np.float32).reshape((depth_msg.height, depth_msg.width))
                # float íƒ€ì…ì€ ì´ë¯¸ ë¯¸í„° ë‹¨ìœ„ì´ë¯€ë¡œ, uint16ìœ¼ë¡œ ë³€í™˜ (mm ë‹¨ìœ„ë¡œ)
                self.depth_image = (self.depth_image * 1000.0).astype(np.uint16)
            else:
                self.get_logger().warn(f"Unsupported depth encoding: {depth_msg.encoding}")
                return
        except Exception as e:
            self.get_logger().warn(f"Depth image conversion failed: {e}")
            return
        
        # YOLO ì¶”ë¡ 
        results = self.model(self.rgb, conf=self.yolo_conf, verbose=False)
        
        if len(results) == 0 or results[0].keypoints is None:
            # ì‚¬ëŒ ì—†ìœ¼ë©´ ì›ë³¸ ì´ë¯¸ì§€ ë°œí–‰
            
            # debug_msg = self.bridge.cv2_to_imgmsg(bgr, encoding="bgr8")
            debug_msg = Image()
            debug_msg.data = self.bgr.tobytes()
            debug_msg.height = self.bgr.shape[0]
            debug_msg.width = self.bgr.shape[1]
            debug_msg.encoding = "bgr8"
            debug_msg.step = self.bgr.shape[1] * 3
            debug_msg.header = image_msg.header
            self.pub_debug.publish(debug_msg)
            return
        
        # ê²°ê³¼ ì´ë¯¸ì§€ (YOLO ê¸°ë³¸ í”Œë¡¯)
        annotated = results[0].plot()
        
        keypoints_data = results[0].keypoints.data.cpu().numpy()  # (N, 17, 3)
        boxes = results[0].boxes.xyxy.cpu().numpy() if results[0].boxes is not None else None
        
        all_markers = MarkerArray()
        all_states = []
        hand_up_found = False  # ì´ë²ˆ í”„ë ˆì„ì—ì„œ hand up ê°ì§€ ì—¬ë¶€
        hand_up_bbox = None  # hand upí•œ ì‚¬ëŒì˜ bbox
        
        for person_idx, kp in enumerate(keypoints_data):
            # 3D ìŠ¤ì¼ˆë ˆí†¤ ì¶”ì¶œ
            skeleton = self.extract_skeleton_3d(kp, self.bgr.shape)
            
            if len(skeleton.keypoints) < 5:
                continue
            
            # ìƒíƒœ íŒë³„
            state, angles = self.state_detector.detect_state(skeleton)
            all_states.append(f"P{person_idx}:{state.name}")
            
            # Hand up ìƒíƒœ í™•ì¸
            if state in [HumanState.HAND_UP_LEFT, HumanState.HAND_UP_RIGHT, HumanState.HAND_UP_BOTH]:
                hand_up_found = True
                # ì²« ë²ˆì§¸ hand up ì‚¬ëŒì˜ bbox ì €ì¥
                if hand_up_bbox is None and boxes is not None and person_idx < len(boxes):
                    hand_up_bbox = boxes[person_idx]  # [x1, y1, x2, y2]
            
            # ë””ë²„ê·¸ ì´ë¯¸ì§€ì— ìƒíƒœ ê·¸ë¦¬ê¸°
            if boxes is not None and person_idx < len(boxes):
                annotated = self.draw_state_on_image(
                    annotated, boxes[person_idx], state, person_idx, angles
                )
            
            # ë§ˆì»¤ ìƒì„±
            if self.publish_markers:
                markers = self.create_skeleton_markers(skeleton, person_idx, state, image_msg.header.stamp)
                all_markers.markers.extend(markers.markers)
        
        # ìƒíƒœ ë°œí–‰
        if all_states:
            state_msg = String()
            state_msg.data = ", ".join(all_states)
            self.pub_state.publish(state_msg)
        
        # ë§ˆì»¤ ë°œí–‰
        if self.publish_markers and all_markers.markers:
            self.pub_markers.publish(all_markers)
        
        # Hand up ê°•ê±´ì„± ê²€ì¦ (5í”„ë ˆì„ ì´ìƒ ê°ì§€)
        if hand_up_found:
            self.hand_up_counter += 1
            if self.hand_up_counter >= self.min_detection_frames and not self.hand_up_detected:
                self.hand_up_detected = True
                self.get_logger().info(f"âœ‹ Hand up detected for {self.min_detection_frames} consecutive frames!")
                
                # Bool ë©”ì‹œì§€ ë°œí–‰
                hand_up_msg = Bool()
                hand_up_msg.data = True
                self.pub_hand_up.publish(hand_up_msg)
                
                # Bbox ë°œí–‰ (x1, y1, x2, y2)
                if hand_up_bbox is not None:
                    bbox_msg = Float32MultiArray()
                    bbox_msg.data = [float(hand_up_bbox[0]), float(hand_up_bbox[1]), 
                                     float(hand_up_bbox[2]), float(hand_up_bbox[3])]
                    self.pub_hand_up_bbox.publish(bbox_msg)
                    self.get_logger().info(f"ğŸ“¦ Published hand up bbox: [{hand_up_bbox[0]:.1f}, {hand_up_bbox[1]:.1f}, {hand_up_bbox[2]:.1f}, {hand_up_bbox[3]:.1f}]")
        else:
            if self.hand_up_counter > 0:
                self.get_logger().debug(f"Hand up counter reset from {self.hand_up_counter}")
            self.hand_up_counter = 0
            self.hand_up_detected = False
        
        # ë””ë²„ê·¸ ì´ë¯¸ì§€ ë°œí–‰
        #debug_msg = self.bridge.cv2_to_imgmsg(annotated, encoding="bgr8")
        debug_msg = Image()
        debug_msg.data = annotated.tobytes()
        debug_msg.height = annotated.shape[0]
        debug_msg.width = annotated.shape[1]
        debug_msg.encoding = "bgr8"
        debug_msg.step = annotated.shape[1] * 3
        debug_msg.header = image_msg.header
        self.pub_debug.publish(debug_msg)


def main(args=None):
    rclpy.init(args=args)
    node = HumanStateDetectorNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
